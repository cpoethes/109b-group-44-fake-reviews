{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone 2: Acquire and Understand the Data\n",
    "\n",
    "Project Group Members:\n",
    "- Geoffrey Humphreys\n",
    "- Amir Koupaei\n",
    "- Chris Moon\n",
    "- Connor Poetzinger\n",
    "\n",
    "Wednesday, March 27, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code and analysis for the second milestone of our project. The objective of this milestone focuses on preparing the [data set](https://www.kaggle.com/datasets/mexwell/fake-reviews-dataset) for subsequent analysis. For submission, follow the Milestone Checklist below.\n",
    "\n",
    "**Milestone Checklist:**\n",
    "- Access: Download, collect, or scrape* the dataset from the relevant source(s).\n",
    "  - **Achieved by downloading the dataset from Kaggle.**\n",
    "- Load: Start a new Jupyter Notebook, import necessary Python libraries and load your data set for inspection.\n",
    "  - **Achieved by using the `pandas` library to load the dataset.**\n",
    "- Understand: Examine the dataset. Ensure you understand the different features and their data types.\n",
    "  - **Achieved by previewing the data, examining summary statistics, data types, missing values, and more**\n",
    "- Preprocessing: Document any cleaning or preprocessing setup that may be necessary/required. This portion only includes the preprocessing steps, not the actual execution of the steps.\n",
    "  - **Achieved by identifying and documenting the preprocessing steps necessary for the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Information and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our group project, we are focusing on the critical task of distinguishing between genuine and counterfeit product reviews leveraging a specially curated dataset designed to mirror the complexities and nuances found in real-world online review platforms. This dataset contains a balanced collection of 40,000 product reviews, equally divided into two distinct categories:\n",
    "- **Original Reviews**: Genuine product reviews written by real customers.\n",
    "**Computer-Generated Fake Reviews**: Counterfeit product reviews generated by an algorithm.\n",
    "\n",
    "Each review in the dataset is annotated according to its source category (OR or GC), enabling us to train and evaluate machine learning models to classify reviews as genuine or counterfeit. The dataset is stored in a CSV file, with each row representing a single review and containing the following columns:\n",
    "1. `category`: Product category\n",
    "2. `rating`: Rating of the product\n",
    "3. `label`: Label indicating whether the review is fake or real\n",
    "4. `text`: Review text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available in a CSV file named `fake_reviews.csv`. We will load the data into a pandas DataFrame and examine the first few rows to understand the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/connorpoetzinger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/connorpoetzinger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40432, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/raw/fake reviews dataset.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rows:** 40,432\n",
    "- **Columns:** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I had read some reviews saying that this bra r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I wasn't sure exactly what it would be. It is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40429</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>You can wear the hood by itself, wear it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40430</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I liked nothing about this dress. The only rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40431</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I work in the wedding industry and have to wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "40427  Clothing_Shoes_and_Jewelry_5     4.0    OR   \n",
       "40428  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "40429  Clothing_Shoes_and_Jewelry_5     2.0    OR   \n",
       "40430  Clothing_Shoes_and_Jewelry_5     1.0    CG   \n",
       "40431  Clothing_Shoes_and_Jewelry_5     5.0    OR   \n",
       "\n",
       "                                                   text_  \n",
       "40427  I had read some reviews saying that this bra r...  \n",
       "40428  I wasn't sure exactly what it would be. It is ...  \n",
       "40429  You can wear the hood by itself, wear it with ...  \n",
       "40430  I liked nothing about this dress. The only rea...  \n",
       "40431  I work in the wedding industry and have to wor...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8743</th>\n",
       "      <td>Electronics_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I have upgraded 8mm to 13mm and the picture is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19060</th>\n",
       "      <td>Tools_and_Home_Improvement_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>This shower head is fantastic.  My other showe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14881</th>\n",
       "      <td>Movies_and_TV_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>Why tinker with a masterpiece? This original m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37268</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>Good comfortable house slipper that doesn't br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>Pet_Supplies_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I bought these to help my puppy, she has a sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "8743                  Electronics_5     5.0    CG   \n",
       "19060  Tools_and_Home_Improvement_5     5.0    OR   \n",
       "14881               Movies_and_TV_5     5.0    OR   \n",
       "37268  Clothing_Shoes_and_Jewelry_5     4.0    OR   \n",
       "19990                Pet_Supplies_5     5.0    CG   \n",
       "\n",
       "                                                   text_  \n",
       "8743   I have upgraded 8mm to 13mm and the picture is...  \n",
       "19060  This shower head is fantastic.  My other showe...  \n",
       "14881  Why tinker with a masterpiece? This original m...  \n",
       "37268  Good comfortable house slipper that doesn't br...  \n",
       "19990  I bought these to help my puppy, she has a sen...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By previewing the data, we can see there are reviews for various product categories with a rating between 1 and 5. The `text_` column contains the review text with messy data that will require preprocessing to clean and prepare for analysis. For this type of task (cleaning unstructured text data), we will need to use natural language processing (NLP) techniques to process the text data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    0.0\n",
       "rating      0.0\n",
       "label       0.0\n",
       "text_       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40432 entries, 0 to 40431\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   category  40432 non-null  object \n",
      " 1   rating    40432 non-null  float64\n",
      " 2   label     40432 non-null  object \n",
      " 3   text_     40432 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Kindle_Store_5                  4730\n",
       "Books_5                         4370\n",
       "Pet_Supplies_5                  4254\n",
       "Home_and_Kitchen_5              4056\n",
       "Electronics_5                   3988\n",
       "Sports_and_Outdoors_5           3946\n",
       "Tools_and_Home_Improvement_5    3858\n",
       "Clothing_Shoes_and_Jewelry_5    3848\n",
       "Toys_and_Games_5                3794\n",
       "Movies_and_TV_5                 3588\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "CG    20216\n",
       "OR    20216\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.256579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.144354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  40432.000000\n",
       "mean       4.256579\n",
       "std        1.144354\n",
       "min        1.000000\n",
       "25%        4.000000\n",
       "50%        5.000000\n",
       "75%        5.000000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky for us, the dataset contains no missing values, its classes are balances, and the data types are easy to work with. We can focus on cleaning the text data and preparing it for analysis. The independent structured data columns (`category`, `rating`) will be useful for exploratory data analysis (EDA) and feature engineering. For modeling, we should consider One Hot encoding the `category` column and standardizing the `rating` column. The dependent variable `label` will be Label Encoded to prepare for classification modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the preprocessing steps necessary for the dataset. SKlearn's custom transformers will be used to implement these steps in the subsequent milestone. The preprocessing steps include:\n",
    "1. **Text Cleaning**: Remove special characters, punctuation, stopwords, and perform lemmatization. The package `nltk` will be used for this task.\n",
    "2. **One-Hot Encoding**: Encode the `category` column using one-hot encoding.\n",
    "3. **Standardization**: Standardize the `rating` column to ensure all features are on the same scale.\n",
    "4. **Label Encoding**: Encode the `label` column to convert the target variable into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleanerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        # Using pandarallel for parallel processing\n",
    "        X_copy[self.column_name] = X_copy[self.column_name].parallel_apply(\n",
    "            self.clean_text\n",
    "        )\n",
    "        return X_copy\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
    "        text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)  # Remove URLs\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Keep only alphabets\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenization\n",
    "        tokens = [\n",
    "            word for word in tokens if word.lower() not in stopwords.words(\"english\")\n",
    "        ]  # Remove stopwords\n",
    "        return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "        self.encoder = OneHotEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder.fit(X[[self.column_name]])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        encoded = self.encoder.transform(X[[self.column_name]]).toarray()\n",
    "        for i, category in enumerate(self.encoder.categories_[0]):\n",
    "            X_copy[category] = encoded[:, i]\n",
    "        X_copy.drop(columns=[self.column_name], inplace=True)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScalerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[[self.column_name]])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.column_name] = self.scaler.transform(X[[self.column_name]])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.label_encoder.fit(X[self.column_name])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.column_name] = 1 - self.label_encoder.transform(X[self.column_name])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(\n",
    "    df,\n",
    "    text_clean=True,\n",
    "    one_hot_encode=True,\n",
    "    standardize=True,\n",
    "    encode_label=True,\n",
    "    text_column=None,\n",
    "    category_column=None,\n",
    "    numerical_column=None,\n",
    "    label_column=None,\n",
    "):\n",
    "    if text_clean and text_column:\n",
    "        text_cleaner = TextCleanerTransformer(column_name=text_column)\n",
    "        df = text_cleaner.transform(df)\n",
    "\n",
    "    if one_hot_encode and category_column:\n",
    "        one_hot_encoder = OneHotEncoderTransformer(column_name=category_column)\n",
    "        one_hot_encoder.fit(df)\n",
    "        df = one_hot_encoder.transform(df)\n",
    "\n",
    "    if standardize and numerical_column:\n",
    "        scaler = StandardScalerTransformer(column_name=numerical_column)\n",
    "        scaler.fit(df)\n",
    "        df = scaler.transform(df)\n",
    "\n",
    "    if encode_label and label_column:\n",
    "        label_encoder = LabelEncoderTransformer(column_name=label_column)\n",
    "        label_encoder.fit(df)\n",
    "        df = label_encoder.transform(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205a32e61acd408eb36a836ab6e3540e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=5054), Label(value='0 / 5054'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
      "/var/folders/hs/fzl95sf10h97wf9qx9p0vfnr0000gn/T/ipykernel_26502/2516610506.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations\n",
    "transformed_df = apply_transformations(\n",
    "    df,\n",
    "    text_column=\"text_\",\n",
    "    category_column=\"category\",\n",
    "    numerical_column=\"rating\",\n",
    "    label_column=\"label\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>Books_5</th>\n",
       "      <th>Clothing_Shoes_and_Jewelry_5</th>\n",
       "      <th>Electronics_5</th>\n",
       "      <th>Home_and_Kitchen_5</th>\n",
       "      <th>Kindle_Store_5</th>\n",
       "      <th>Movies_and_TV_5</th>\n",
       "      <th>Pet_Supplies_5</th>\n",
       "      <th>Sports_and_Outdoors_5</th>\n",
       "      <th>Tools_and_Home_Improvement_5</th>\n",
       "      <th>Toys_and_Games_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>1</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>1</td>\n",
       "      <td>love great upgrade original ive mine couple years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>1</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.845815</td>\n",
       "      <td>1</td>\n",
       "      <td>missing information use great product price</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>1</td>\n",
       "      <td>nice set good quality set two months</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>-0.224216</td>\n",
       "      <td>0</td>\n",
       "      <td>read reviews saying bra ran small ordered two ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>1</td>\n",
       "      <td>wasnt sure exactly would little large small si...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40429</th>\n",
       "      <td>-1.971948</td>\n",
       "      <td>0</td>\n",
       "      <td>wear hood wear hood wear jacket without hood s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40430</th>\n",
       "      <td>-2.845815</td>\n",
       "      <td>1</td>\n",
       "      <td>liked nothing dress reason gave stars ordered ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40431</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>0</td>\n",
       "      <td>work wedding industry work long days feet outs...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40432 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating  label                                              text_  \\\n",
       "0      0.649651      1  love well made sturdy comfortable love itvery ...   \n",
       "1      0.649651      1  love great upgrade original ive mine couple years   \n",
       "2      0.649651      1            pillow saved back love look feel pillow   \n",
       "3     -2.845815      1        missing information use great product price   \n",
       "4      0.649651      1               nice set good quality set two months   \n",
       "...         ...    ...                                                ...   \n",
       "40427 -0.224216      0  read reviews saying bra ran small ordered two ...   \n",
       "40428  0.649651      1  wasnt sure exactly would little large small si...   \n",
       "40429 -1.971948      0  wear hood wear hood wear jacket without hood s...   \n",
       "40430 -2.845815      1  liked nothing dress reason gave stars ordered ...   \n",
       "40431  0.649651      0  work wedding industry work long days feet outs...   \n",
       "\n",
       "       Books_5  Clothing_Shoes_and_Jewelry_5  Electronics_5  \\\n",
       "0          0.0                           0.0            0.0   \n",
       "1          0.0                           0.0            0.0   \n",
       "2          0.0                           0.0            0.0   \n",
       "3          0.0                           0.0            0.0   \n",
       "4          0.0                           0.0            0.0   \n",
       "...        ...                           ...            ...   \n",
       "40427      0.0                           1.0            0.0   \n",
       "40428      0.0                           1.0            0.0   \n",
       "40429      0.0                           1.0            0.0   \n",
       "40430      0.0                           1.0            0.0   \n",
       "40431      0.0                           1.0            0.0   \n",
       "\n",
       "       Home_and_Kitchen_5  Kindle_Store_5  Movies_and_TV_5  Pet_Supplies_5  \\\n",
       "0                     1.0             0.0              0.0             0.0   \n",
       "1                     1.0             0.0              0.0             0.0   \n",
       "2                     1.0             0.0              0.0             0.0   \n",
       "3                     1.0             0.0              0.0             0.0   \n",
       "4                     1.0             0.0              0.0             0.0   \n",
       "...                   ...             ...              ...             ...   \n",
       "40427                 0.0             0.0              0.0             0.0   \n",
       "40428                 0.0             0.0              0.0             0.0   \n",
       "40429                 0.0             0.0              0.0             0.0   \n",
       "40430                 0.0             0.0              0.0             0.0   \n",
       "40431                 0.0             0.0              0.0             0.0   \n",
       "\n",
       "       Sports_and_Outdoors_5  Tools_and_Home_Improvement_5  Toys_and_Games_5  \n",
       "0                        0.0                           0.0               0.0  \n",
       "1                        0.0                           0.0               0.0  \n",
       "2                        0.0                           0.0               0.0  \n",
       "3                        0.0                           0.0               0.0  \n",
       "4                        0.0                           0.0               0.0  \n",
       "...                      ...                           ...               ...  \n",
       "40427                    0.0                           0.0               0.0  \n",
       "40428                    0.0                           0.0               0.0  \n",
       "40429                    0.0                           0.0               0.0  \n",
       "40430                    0.0                           0.0               0.0  \n",
       "40431                    0.0                           0.0               0.0  \n",
       "\n",
       "[40432 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv(\"../../data/processed/processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this milestone of our project, our team successfully acquired and prepared our dataset for subsequent analysis. The data was sourced from Kaggle, obtaining a collection of over forty thousand product reviews divided into Original Reviews(OR) and Computer-Generated Fake Reviews(GC). Each review was accompanied by essential features such as product category, rating, label (indicating whether it's genuine or fake), and the review text itself. Upon loading the data into a pandas DataFrame, the first priority was to gain a deep understanding of the structure and content.\n",
    "\n",
    "Through examination, it was confirmed that the integrity of the dataset was intact, with no missing values, balanced classes, and straightforward data types. The data was then preprocessed to clean the text data, one-hot encode the `category` column, standardize the `rating` column, and label encode the `label` column. These preprocessing steps will be implemented in the subsequent milestone using custom transformers from the `sklearn` library. Custom transformers will allow us to streamline the preprocessing steps and fit into a machine learning pipeline for model training and evaluation.\n",
    "\n",
    "The next milestone will focus on exploratory data analysis (EDA) to gain insights into the data and feature engineering to create new features that may improve model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "109b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
